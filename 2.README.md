# Overview

- Additional explanations and plots for a DeepMind-style RL model.
- Hyperparameter tuning performed using Optuna.
- Further details on the reward function are provided.

# Models - State penalty DM and Action penalty DM
## Action DM: 
This model penalizes high frequency action (torque). It works by passing actions through a LPF filter, and extracts the high frequency difference. The energy is calculated, sigmoided, and integrated in the reward function.

## State DM: 
This models also uses the same approach, but applied to the state (angle). Same energy and sigmoid implementation. 

Models and results are also uploaded to [Neptune](https://app.neptune.ai/rl-gaussian-sac/rl-gaussian-sac/) for result reproducibility. 

# Reward Function Explanation

![Base Reward Function](https://raw.githubusercontent.com/Arush-Pimpalkar/RL_Arush/main/plots/base_reward_function.png)


The angle term ($\theta$) is assigned unit weight to define the primary regulation objective. The angular velocity term ($\dot{\theta}$) is downweighted to account for its larger numerical scale and to provide appropriate damping, consistent with the pendulumâ€™s natural frequency. The control penalty ($u$) is chosen several orders of magnitude smaller to regularize the policy without inhibiting stabilization, matching the torque scale required to counteract gravity. Together, these weights approximate a quadratic energy-based cost, closely related to LQR and classical damping design, ensuring physically meaningful and stable behavior.


## Reward Function with High-Frequency Penalty

The reward function used in this model:

![DM reward function](https://raw.githubusercontent.com/Arush-Pimpalkar/RL_Arush/main/plots/DM_reward_function.png)

Integrating the high-frequency component with the base reward function in a multiplicative manner led to instability during training and rollouts. Therefore, an additive formula is used.

# Additional Plots



![state_ASD_DM](https://raw.githubusercontent.com/Arush-Pimpalkar/RL_Arush/main/plots/state_ASD_DM.png)

![action_ASD_DM](https://raw.githubusercontent.com/Arush-Pimpalkar/RL_Arush/main/plots/action_ASD_DM.png)

![noise_action_DM](https://raw.githubusercontent.com/Arush-Pimpalkar/RL_Arush/main/plots/noise_vs_action.png)
